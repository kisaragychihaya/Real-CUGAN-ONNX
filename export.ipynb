{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt0hTC0eyJX-"
   },
   "source": [
    "Step 1: Preparation \n",
    "\n",
    "Before you begin, make sure that you have set the runtime type to GPU  (Hardware acclerator: GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8DyiIfxxF3Ey",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"ailab/Real-CUGAN\")\n",
    "ROOTPATH=\"./\" # root dir (a constant)\n",
    "ModelPath=ROOTPATH+\"weights_v3/\" # model dir\n",
    "PendingPath=ROOTPATH+\"pending/\" # input dir\n",
    "FinishPath=ROOTPATH+\"finish/\" # output dir\n",
    "ModelName=\"pro-conservative-up2x.pth\" # default model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zjBE_P0yQ5M"
   },
   "source": [
    "Step 2: Download model files from [here](https://drive.google.com/drive/folders/1UFgpV14uEAcgYvVw0fJuajzy1k7JIz6H) and save them - in a folder called `weights_v3` \n",
    "\n",
    "Step 3: Put/upload your image(s) under `pending`.\n",
    "\n",
    "Then, run the following and choose the model you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tMWiga8GOhMz",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending images:\n",
      "\t632d634919cab145f2372a3196665957~tplv-dy-resize-origshort-autoq-75_330.jpeg\n",
      "Model files available:\n",
      "1. \t pro-conservative-up2x.pth\n",
      "2. \t pro-denoise3x-up3x.pth\n",
      "3. \t pro-conservative-up3x.pth\n",
      "4. \t pro-denoise3x-up2x.pth\n",
      "5. \t pro-no-denoise-up3x.pth\n",
      "6. \t pro-no-denoise-up2x.pth\n",
      "7. \t up3x-latest-conservative.pth\n",
      "8. \t up2x-latest-no-denoise.pth\n",
      "9. \t up2x-latest-denoise3x.pth\n",
      "10. \t up3x-latest-denoise3x.pth\n",
      "11. \t up3x-latest-no-denoise.pth\n",
      "12. \t up4x-latest-conservative.pth\n",
      "13. \t up4x-latest-denoise3x.pth\n",
      "14. \t up2x-latest-denoise1x.pth\n",
      "15. \t up4x-latest-no-denoise.pth\n",
      "16. \t up2x-latest-conservative.pth\n",
      "17. \t up2x-latest-denoise2x.pth\n"
     ]
    }
   ],
   "source": [
    "import glob,os\n",
    "fileNames = os.listdir(PendingPath)\n",
    "print(\"Pending images:\")\n",
    "for i in fileNames:\n",
    "    print(\"\\t\"+i)\n",
    "fileNames = glob.glob(ModelPath+\"/*.pth\")\n",
    "print(\"Model files available:\")\n",
    "models=[]\n",
    "for idx, i in enumerate(fileNames):\n",
    "    print(f\"{idx+1}. \\t {os.path.split(i)[1]}\")\n",
    "    models.append(os.path.split(i)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_JcZ1RAyZtU"
   },
   "source": [
    "Step 4: Run the processing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v0ip7SPmI8nj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model ./weights_v3/pro-conservative-up2x.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/ailab/Real-CUGAN/upcunet_v3.py:267: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (w0 != pw or h0 != ph): x = x[:, :, :h0 * 2, :w0 * 2]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:1209: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model ./weights_v3/pro-denoise3x-up3x.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/ailab/Real-CUGAN/upcunet_v3.py:595: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (w0 != pw or h0 != ph): x = x[:, :, :h0 * 3, :w0 * 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model ./weights_v3/pro-conservative-up3x.pth\n",
      "using model ./weights_v3/pro-denoise3x-up2x.pth\n",
      "using model ./weights_v3/pro-no-denoise-up3x.pth\n",
      "using model ./weights_v3/pro-no-denoise-up2x.pth\n",
      "using model ./weights_v3/up3x-latest-conservative.pth\n",
      "using model ./weights_v3/up2x-latest-no-denoise.pth\n",
      "using model ./weights_v3/up2x-latest-denoise3x.pth\n",
      "using model ./weights_v3/up3x-latest-denoise3x.pth\n",
      "using model ./weights_v3/up3x-latest-no-denoise.pth\n",
      "using model ./weights_v3/up4x-latest-conservative.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/ailab/Real-CUGAN/upcunet_v3.py:926: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (w0 != pw or h0 != ph): x = x[:, :, :h0 * 4, :w0 * 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model ./weights_v3/up4x-latest-denoise3x.pth\n",
      "using model ./weights_v3/up2x-latest-denoise1x.pth\n",
      "using model ./weights_v3/up4x-latest-no-denoise.pth\n",
      "using model ./weights_v3/up2x-latest-conservative.pth\n",
      "using model ./weights_v3/up2x-latest-denoise2x.pth\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from upcunet_v3 import RealWaifuUpScaler\n",
    "from time import time as ttime\n",
    "from torch import nn\n",
    "fileNames = os.listdir(PendingPath)\n",
    "class M2(nn.Module):\n",
    "    def __init__(self,m,pro):\n",
    "        super().__init__()\n",
    "        self.m=m\n",
    "        self.pro=pro\n",
    "    def forward(self,x):\n",
    "        x=torch.permute(x,(0,3,1,2))\n",
    "        if self.pro:\n",
    "            x=x.half() / (255/0.7)+0.15\n",
    "        else:\n",
    "            x=x.half() / 255\n",
    "        return torch.permute(m.forward_fast_rough(x,0,1,True),(0,2,3,1))\n",
    "for ModelName in models:\n",
    "    print(f\"using model {ModelPath+ModelName}\")\n",
    "    scale=int(ModelName[ModelName.find(\"up\")+2])\n",
    "    upscaler = RealWaifuUpScaler(scale, ModelPath+ModelName, half=True, device=\"cuda:0\")\n",
    "    pro=upscaler.pro\n",
    "    m=upscaler.model\n",
    "    m2=M2(m,pro)\n",
    "    dummy_input = torch.randn(1,  224, 224,3, device=\"cuda\")\n",
    "    input_names=[\"img\"]\n",
    "    output_names=[\"out\"]\n",
    "    dynamic = {'img': {0: 'batch', 1: 'height', 2: 'width'}}\n",
    "    dynamic['out'] = {0: 'batch', 1: 'out_height', 2: 'out_width'}\n",
    "    torch.onnx.export(m2, dummy_input, ModelName+\".onnx\", verbose=False, \n",
    "                  input_names=input_names, \n",
    "                  output_names=output_names,\n",
    "                  opset_version=15,\n",
    "                  dynamic_axes=dynamic or None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yYUAiIzzCaC"
   },
   "source": [
    "Generated images should be under /content/aliab/Real-CUGAN/finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "m2=M2(m)\n",
    "import torch\n",
    "dummy_input = torch.randn(1,  224, 224,3, device=\"cuda\")\n",
    "\n",
    "\n",
    "input_names=[\"img\"]\n",
    "output_names=[\"out\"]\n",
    "dynamic = {'img': {0: 'batch', 1: 'height', 2: 'width'}}\n",
    "dynamic['out'] = {0: 'batch', 2: 'out_height', 3: 'out_width'}\n",
    "torch.onnx.export(m2, dummy_input, ModelName+\".onnx\", verbose=False, \n",
    "                  input_names=input_names, \n",
    "                  output_names=output_names,\n",
    "                  opset_version=15,\n",
    "                  dynamic_axes=dynamic or None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Real-CUGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
